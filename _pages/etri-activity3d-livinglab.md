---
permalink: /etri-activity3d-livinglab/
layout: splash
title: ETRI-Activity3D-LivingLab
header:
  overlay_color: rgba(23,165,137, 0.5)
  overlay_filter: rgba(255, 0, 0, 0.3)
author_profile: false
last_modified_at: 2020-10-19T12:30:03-05:00
toc: true
---

# 로봇환경에서 고령자의 일상행동 인식을 위한 3D 영상 데이터셋
# 고령자가 실제 생활하는 주거 환경에서 구축한 실환경 데이터셋

## 구축 배경
  
  고령자케어 로봇을 위한 최신 기법의 연구를 위해서는 로봇 시점에서 고령자를 촬영한 데이터셋의 확보가 필수적이다. 하지만 로봇이 운용되는 환경에서 사람의 일상 행동을 인식하기 위한 데이터셋은 매우 부족하며 특히 고령자 대상의 데이터셋은 전무한 실정이다.
    
ETRI는 고령자케어 로봇을 위한 행동 인식 연구를 위해 2017년부터 다양한 환경에서 3차원 영상 데이터셋을 구축해왔다. 고령자가 실제 생활하는 주거 환경과 이를 모사한 아파트 테스트베드 환경 및 가상 환경에서 고령자의 행동 데이터를 확보하는 연구를 수행 중이다.
    
연구진은 이들 중 아파트 테스트베드 환경에서 구축한 ETRI-Activity3D 데이터셋을 2019년 11월에 공개하였다. ETRI-Activity3D 데이터셋은 100명의 참가자가 행한 55가지 일상 행동이 포함된 3차원 영상 데이터셋이다. 수집된 데이터의 개수는 총 112,620개이며 이는 로봇 시점으로 촬영된 세계 최대 규모의 3D 영상 데이터셋이다. 데이터가 공개된 이후에 고령자의 행동을 연구하는 국내외 다수의 기업, 학교, 연구소에서 본 데이터셋을 활용하여 다양한 연구를 수행하고 있다.
    
ETRI-Activity3D-LivingLab 데이터셋은 테스트베드가 아닌 고령자가 실제 생활하는 주거 환경에서 구축한 실환경 데이터셋이다. 독거 고령자가 실제 생활하는 50곳의 가정을 방문하여 상용화 기술 연구에 필수적인 실환경 3차원 영상 데이터셋 8,622개를 구축하였다.
    
## 소개

<figure>
  <img src="/assets/livinglab-data-samples.png" alt="data-samples"/>
  <figcaption>[그림1] 본 데이터셋에 포함된 샘플 데이터를 보여준다. RGB 비디오에서 추출한 샘플 프레임과 각 샘플 프레임에 대응되는 깊이영상, 바디인덱스, 관절의 위치를 보여준다. 휴먼이 행하는 행동은 좌상단부터 시계 방향으로 “약 먹기”, “진공청소기 사용하기”, “리모컨으로 TV 컨트롤하기”, “상의 벗기” 이다.</figcaption>
</figure>

본 데이터셋은 고령자케어 로봇을 위한 행동 인식 기술의 실환경 성능을 평가하기 위한 RGB-D 데이터셋이다. 따라서 고령자가 실제 생활하는 50개의 가정을 직접 방문하여 구축하였다.  
  
고령자가 수행하는 일상 행동 55종에 대하여 Kinect v2 카메라를 이용하여 RGB 비디오, 깊이영상, 바디인덱스, 그리고 3차원 관절의 위치를 획득하였다. 최종적으로 8,622 셋의 3차원 데이터를 확보하였다.  
  
본 데이터셋은 고령자의 실주거 환경에서 로봇 시점으로 촬영된 세계 최초의 3D 행동인식 데이터셋이라는 점에서 의미가 있다.  
  
본 연구진은 ETRI-Activity3D-LivingLab 데이터셋이 2019년 공개된 ETRI-Activity3D 데이터셋과 함께 활용되어 로봇 인공지능 기술의 상용화 연구에 기여할 수 있기를 기대한다.  

| 항목 | 내용 |
| :-: | :-: |
| 총 샘플의 개수 | 8,622 셋 |
| 인식 대상 행동 클래스 | 55개 |
| 촬영자 수 | 50명 (남 8명, 여 42명) |
| 수집 환경 | 독거 고령자가 실제 생활하는 가정 |
| 촬영 장소 | 로봇이 위치할 수 있는 다양한 장소 |
| 수집 데이터 포맷 | RGB videos, depth map frames, body index frames, 3D skeletal data |
| 촬영 카메라 | Kinect v2 |

본 데이터셋의 샘플 영상을 아래 링크에서 다운받아 볼 수 있다.

* [ETRI-Activity3D-Living_Samples](https://etri.gov-dooray.com/share/drive-files/kdhawuidbrbd.j4OKzXWQSO6f-4Si_1GA8w){: target="_blank" }

## 인식 대상 행동

70세 이상의 고령자 53명의 자택을 방문하여 기상부터 취침까지의 하루 행동을 직접 관찰하고 기록하였더니 총 245개의 일상 활동 유형으로 압축되었다. 이들 행동 중에 빈번하게 나타나는 행동으로 TV 시청, 식사관련 활동, 화장실 사용, 식사 준비, 전화 통화, 약 복용, 요리, 청소 등이 있었으며 이러한 다빈도 활동들을 기준으로 55종의 행동을 인식 대상으로 선정하였다.

<figure>
  <img src="/resources/activities_55.png" alt="activities_55"/>
</figure>

## 데이터 포맷

수집된 데이터는 Kinect v2 센서로 획득한 RGB 비디오, 깊이영상, 바디인텍스, 3차원 관절위치이며 동기화 되어 저장된다.

|  Collected Data   | Resolution | File Format |         Size |
| :---------------: | :--------: | :---------: | -----------: |
|    RGB Videos     | 1920x1080  |     MP4     |       42.4GB |
| Depth Map Frames  |  512x424   |     PNG     |     512.20GB |
| Body Index Frames |  512x424   |     PNG     |       7.04GB |
| 3D Skeletal Data  | 25 joints  |     CSV     |       5.49GB |
|                   |            |  **Total**  | **567.13GB** |

## 수집 환경

본 데이터셋은 로봇이 실제로 서비스하는 상황을 최대한 반영한다는 목표를 가지고 수집되었다.

가정용 서비스 로봇의 높이를 고려하여 70cm 와 120cm 높이에 Kinect v2 센서가 설치된 2대의 촬영 장비를 제작하였다. 촬영 장치는 로봇이 서비스 하는 상황에서 존재할 수 있는 다양한 위치에 배치한다. 촬영 장치와 대상자의 거리는 1.5m에서 3.5m까지 다양하다. 행동의 아이디와 카메라 높이는 각 비디오 샘플의 파일 이름으로 제공된다.

## 다운로드

아래의 문서를 확인하여 다운로드 바랍니다.

* **가이드라인** [다운로드](/resources/livinglab-guideline.pdf){: target="_blank" }

## 담당자 연락처

* 이름: 김도형 책임연구원
* 이메일: dhkim008@etri.re.kr
* 전화번호: 042-860-5873
* 소속: 한국전자통신연구원 지능로보틱스연구본부 인간로봇상호작용연구실

## 주의

* 본 데이터셋은 개인정보보호와 안전한 데이터의 획득/관리를 위해 기관생명윤리위원회(IRB: Institutional Review Board)의 승인을 거쳐 구축되었습니다.
* 본 데이터셋은 과학기술정보통신부 산하 정보통신기획평가원의 “고령 사회에 대응하기 위한 실환경 휴먼케어 로봇 기술 개발(2017-0-00162)” 사업의 일환으로 구축되었습니다.